출력 예시: [track_123, track_456, track_789, track_321, track_654]
```

---

## 2. 전체 흐름 다이어그램
```
┌─────────────────────────────────────────────────────────────┐
│                     입력: 사용자 정보                          │
│  (user_id, 성별, 나이, 좋아한 곡들, 플레이리스트)              │
└────────────────┬────────────────────────────────────────────┘
                 │
                 ▼
        ┌────────────────────┐
        │  User Encoder      │
        │ (사용자 임베딩)     │
        └────────┬───────────┘
                 │
                 ▼
        ┌────────────────────────────────┐
        │  Transformer Layer             │
        │ (사용자 선호 패턴 학습)        │
        │ - Self-Attention               │
        │ - 좋아한 곡들 간의 관계 학습   │
        └────────┬───────────────────────┘
                 │
                 ▼
        ┌────────────────────┐
        │  User Embedding    │
        │ (사용자 벡터 생성)  │
        └────────┬───────────┘
                 │
    ┌────────────┴────────────┐
    │                         │
    ▼                         ▼
스포티파이 곡 1            스포티파이 곡 N
(audio features)        (audio features)
    │                         │
    ▼                         ▼
┌──────────────┐         ┌──────────────┐
│ Song Encoder │         │ Song Encoder │
│ (곡 임베딩)  │         │ (곡 임베딩)  │
└──────┬───────┘         └──────┬───────┘
       │                        │
       └────────────┬───────────┘
                    ▼
        ┌──────────────────────────┐
        │  Matching & Scoring      │
        │ (사용자 벡터와 곡 벡터   │
        │  의 유사도 계산)         │
        └────────┬─────────────────┘
                 │
                 ▼
        ┌──────────────────────────┐
        │  모든 곡의 점수           │
        │ [0.95, 0.87, ..., 0.12] │
        └────────┬─────────────────┘
                 │
                 ▼
        ┌──────────────────────────┐
        │  Top-5 선택              │
        │ (점수 높은 순서대로)     │
        └────────┬─────────────────┘
                 │
                 ▼
   ┌──────────────────────────────┐
   │ 출력: 상위 5개 곡 (순서대로)  │
   │ [track_A, track_B, ...]      │
   └──────────────────────────────┘
```

---

## 3. 각 모듈의 역할 설정

### **3-1. User Encoder (사용자 인코더)**

**입력**: user_id, 성별, 나이, 좋아한 곡들의 audio features

**역할**: 사용자 정보를 하나의 벡터로 변환

**구성**:
- 프로필 임베딩: 성별, 나이를 숫자 벡터로 변환
- 선호 시퀀스 처리: 좋아한 곡들의 audio features를 시간 순서대로 나열
- 결합: 프로필 정보 + 선호 곡들의 특성을 합침

**출력**: 사용자 벡터 (예: 128차원)

---

### **3-2. Transformer Layer (트랜스포머 계층)**

**입력**: User Encoder에서 나온 선호 곡들의 시퀀스

**역할**: 사용자가 좋아한 곡들 간의 관계와 패턴을 학습

**구성**:
- **Self-Attention**: "사용자는 어떤 특성의 곡들을 함께 좋아하는가?" 학습
- **Multi-Head Attention**: 여러 관점에서 동시에 패턴 학습
- **Feed-Forward Network**: 학습한 패턴을 기반으로 사용자 선호도 정제
- **Residual Connection & Layer Normalization**: 안정적인 학습

**예시**:
```
좋아한 곡들: [danceability 높음, energy 높음] 
            [danceability 높음, energy 높음]
            [danceability 낮음, energy 낮음]

Attention 학습 결과:
→ "이 사용자는 danceability가 높은 곡들을 자주 좋아해"
→ "근데 가끔 차분한(energy 낮은) 곡도 좋아함"
```

**출력**: 정제된 사용자 벡터 (예: 128차원)

---

### **3-3. Song Encoder (곡 인코더)**

**입력**: 곡의 audio features (danceability, energy, valence, tempo, acousticness 등)

**역할**: 각 곡을 벡터로 변환

**구성**:
- 선형층(Linear Layer)들을 통해 audio features를 고차원 벡터로 변환
- 활성화 함수(ReLU 등)로 비선형성 추가

**출력**: 곡 벡터 (예: 128차원)

---

### **3-4. Matching & Scoring (매칭 및 점수 계산)**

**입력**: 사용자 벡터 + 곡 벡터

**역할**: 사용자와 곡의 유사도를 계산해서 0~1 사이의 점수 생성

**계산 방법**:
```
점수 = 사용자 벡터와 곡 벡터의 유사도
(코사인 유사도, 내적, 또는 다른 방식 사용 가능)
```

**출력**: 0~1 사이의 점수 (1에 가까울수록 사용자가 좋아할 확률 높음)

---

## 4. 손실함수와 평가지표

### **손실함수 (Loss Function)**

학습 시 모델이 올바르게 학습하고 있는지 측정하는 지표

**방식**: Ranking Loss (순위 손실)
- 모델이 사용자가 좋아한 곡은 높은 점수를, 싫어한 곡은 낮은 점수를 주도록 학습

**예**:
```
좋아한 곡: 점수 0.9 (높음 ✓)
싫어한 곡: 점수 0.2 (낮음 ✓)
→ 손실값 작음 (잘 학습됨)

좋아한 곡: 점수 0.3 (낮음 ✗)
싫어한 곡: 점수 0.8 (높음 ✗)
→ 손실값 큼 (잘못 학습됨)
```

---

### **평가지표 (Evaluation Metrics)**

모델의 성능을 측정하는 지표

1. **Precision@5**: 추천한 5개 곡 중 실제로 사용자가 좋아할 곡의 비율
```
   추천: [곡A, 곡B, 곡C, 곡D, 곡E]
   사용자가 실제 좋아함: [곡A, 곡C]
   Precision@5 = 2/5 = 0.4 (40%)
```

2. **Recall@5**: 사용자가 좋아하는 전체 곡 중 몇 %를 추천했는가
```
   사용자가 실제 좋아하는 곡: [곡A, 곡C, 곡F, 곡G] (4개)
   추천에서 맞춘 것: [곡A, 곡C] (2개)
   Recall@5 = 2/4 = 0.5 (50%)
```

3. **NDCG@5** (Normalized Discounted Cumulative Gain): 순서를 고려한 성능 평가
   - 상위에 올수록 더 중요하다고 간주

---

## 5. 학습 파이프라인 설계
```
┌─────────────────────────────────────┐
│  1. 데이터 준비                      │
│  - 웹사이트 데이터 + Spotify 데이터 │
│  - 학습/검증/테스트 셋 분할        │
└────────────┬────────────────────────┘
             │
             ▼
┌─────────────────────────────────────┐
│  2. 모델 초기화                      │
│  - User Encoder                    │
│  - Transformer Layer               │
│  - Song Encoder                    │
│  - Matching Head                   │
└────────────┬────────────────────────┘
             │
             ▼
┌─────────────────────────────────────┐
│  3. 학습 루프 (여러 에포크 반복)     │
│                                    │
│  각 배치마다:                       │
│  ① 사용자와 곡 정보 입력            │
│  ② 모델이 점수 계산                 │
│  ③ 손실함수로 오류 측정             │
│  ④ 역전파(Backpropagation)로 가중치 │
│     업데이트                        │
└────────────┬────────────────────────┘
             │
             ▼
┌─────────────────────────────────────┐
│  4. 검증 (매 에포크마다)             │
│  - 검증 데이터에서 성능 측정        │
│  - 과적합(Overfitting) 감지         │
└────────────┬────────────────────────┘
             │
             ▼
┌─────────────────────────────────────┐
│  5. 테스트                           │
│  - 최종 모델의 성능 평가             │
│  - Precision@5, Recall@5, NDCG@5   │
└─────────────────────────────────────┘
```

### **학습 하이퍼파라미터**
```
- 에포크 (Epoch): 50~100 (데이터셋 크기에 따라)
- 배치 크기 (Batch Size): 32 또는 64
- 학습률 (Learning Rate): 0.001
- 옵티마이저 (Optimizer): Adam
- Transformer 헤드 개수 (Num Heads): 8
- Transformer 계층 개수 (Num Layers): 2~4
